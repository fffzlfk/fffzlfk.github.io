<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>反向传播 | fffzlfk's Blog</title><meta name=keywords content="NN,Python"><meta name=description content="反向传播 反向传播（英语：Backpropagation，意为误差反向传播，缩写为BP）是对多层人工神经网络进行梯度下降的算法，也就是用链式法则以网络每层的权重为变数计算损失函数的梯度，以更新权重来最小化损失函数。
简单例子计算 符号 $ w_{ij} $ 权重 $ z_i $ 输入 $ y_i $ 输出 $ E = \frac{1}{2}(y_p-y_a)^2$ 损失 $ f(x) = \frac{1}{1+e^{-x}}$ 激活函数 例如更新$w_{53}$
主要思想就是我们无法找到$E$和$w_{53}$的直接关系，所以使用链式求导法则来间接求梯度： $$ w_{53}(new) = w_{53}(old) - \Delta w_{53} $$
$$ \begin{cases} E = \frac{1}{2}(y_5-y_a)^2\\ y_5 = f(z_5)\\ z_5 = w_{53} * y_3 + w_{54} * y_4 \end{cases} $$
$$ \begin{align} \Delta w_{53} &= \frac{\partial E}{\partial w_{53}} \\ &= \frac{\partial E}{\partial y_{5}} \frac{\partial y_5}{\partial z_5} \frac{\partial z_5}{\partial w_{53}} \end{align} $$"><meta name=author content="fffzlfk"><link rel=canonical href=https://fffzlfk.github.io/posts/%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD/><link crossorigin=anonymous href=/assets/css/stylesheet.3b1cc03af9890a9e14762cb10779f50b165a8e12a4ff763213eef0019f3771fb.css integrity="sha256-OxzAOvmJCp4UdiyxB3n1CxZajhKk/3YyE+7wAZ83cfs=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.ab916b8151320cc693135f5df9fe4b75e6e4754d8f0dff5782df332cacd1ba8e.js integrity="sha256-q5FrgVEyDMaTE19d+f5LdebkdU2PDf9Xgt8zLKzRuo4=" onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=https://fffzlfk.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://fffzlfk.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://fffzlfk.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://fffzlfk.github.io/apple_touch_icon.png><link rel=mask-icon href=https://fffzlfk.github.io/favicon.ico><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.css integrity=sha384-MlJdn/WNKDGXveldHDdyRP1R4CTHr3FeuDNfhsLPYrq2t0UBkUdK2jyTnXPEK1NQ crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.js integrity=sha384-VQ8d8WVFw0yHhCk5E8I86oOhv48xLpnDZx5T9GogA/Y84DcCKWXDmSDfn13bzFZY crossorigin=anonymous></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/contrib/auto-render.min.js integrity=sha384-+XBljXPPiv+OzfbB3cVmLHf4hdUFHlWNZN5spNQ7rmHTXpd7WvJum6fIACpNNfIR crossorigin=anonymous></script>
<script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1},{left:"\\[",right:"\\]",display:!0}],throwOnError:!1})})</script><meta property="og:title" content="反向传播"><meta property="og:description" content="反向传播 反向传播（英语：Backpropagation，意为误差反向传播，缩写为BP）是对多层人工神经网络进行梯度下降的算法，也就是用链式法则以网络每层的权重为变数计算损失函数的梯度，以更新权重来最小化损失函数。
简单例子计算 符号 $ w_{ij} $ 权重 $ z_i $ 输入 $ y_i $ 输出 $ E = \frac{1}{2}(y_p-y_a)^2$ 损失 $ f(x) = \frac{1}{1+e^{-x}}$ 激活函数 例如更新$w_{53}$
主要思想就是我们无法找到$E$和$w_{53}$的直接关系，所以使用链式求导法则来间接求梯度： $$ w_{53}(new) = w_{53}(old) - \Delta w_{53} $$
$$ \begin{cases} E = \frac{1}{2}(y_5-y_a)^2\\ y_5 = f(z_5)\\ z_5 = w_{53} * y_3 + w_{54} * y_4 \end{cases} $$
$$ \begin{align} \Delta w_{53} &= \frac{\partial E}{\partial w_{53}} \\ &= \frac{\partial E}{\partial y_{5}} \frac{\partial y_5}{\partial z_5} \frac{\partial z_5}{\partial w_{53}} \end{align} $$"><meta property="og:type" content="article"><meta property="og:url" content="https://fffzlfk.github.io/posts/%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2022-10-18T21:52:39+08:00"><meta property="article:modified_time" content="2022-10-18T21:52:39+08:00"><meta property="og:site_name" content="fffzlfk's Blog"><meta name=twitter:card content="summary"><meta name=twitter:title content="反向传播"><meta name=twitter:description content="反向传播 反向传播（英语：Backpropagation，意为误差反向传播，缩写为BP）是对多层人工神经网络进行梯度下降的算法，也就是用链式法则以网络每层的权重为变数计算损失函数的梯度，以更新权重来最小化损失函数。
简单例子计算 符号 $ w_{ij} $ 权重 $ z_i $ 输入 $ y_i $ 输出 $ E = \frac{1}{2}(y_p-y_a)^2$ 损失 $ f(x) = \frac{1}{1+e^{-x}}$ 激活函数 例如更新$w_{53}$
主要思想就是我们无法找到$E$和$w_{53}$的直接关系，所以使用链式求导法则来间接求梯度： $$ w_{53}(new) = w_{53}(old) - \Delta w_{53} $$
$$ \begin{cases} E = \frac{1}{2}(y_5-y_a)^2\\ y_5 = f(z_5)\\ z_5 = w_{53} * y_3 + w_{54} * y_4 \end{cases} $$
$$ \begin{align} \Delta w_{53} &= \frac{\partial E}{\partial w_{53}} \\ &= \frac{\partial E}{\partial y_{5}} \frac{\partial y_5}{\partial z_5} \frac{\partial z_5}{\partial w_{53}} \end{align} $$"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":2,"name":"Posts","item":"https://fffzlfk.github.io/posts/"},{"@type":"ListItem","position":3,"name":"反向传播","item":"https://fffzlfk.github.io/posts/%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"反向传播","name":"反向传播","description":"反向传播 反向传播（英语：Backpropagation，意为误差反向传播，缩写为BP）是对多层人工神经网络进行梯度下降的算法，也就是用链式法则以网络每层的权重为变数计算损失函数的梯度，以更新权重来最小化损失函数。\n简单例子计算 符号 $ w_{ij} $ 权重 $ z_i $ 输入 $ y_i $ 输出 $ E = \\frac{1}{2}(y_p-y_a)^2$ 损失 $ f(x) = \\frac{1}{1+e^{-x}}$ 激活函数 例如更新$w_{53}$\n主要思想就是我们无法找到$E$和$w_{53}$的直接关系，所以使用链式求导法则来间接求梯度： $$ w_{53}(new) = w_{53}(old) - \\Delta w_{53} $$\n$$ \\begin{cases} E = \\frac{1}{2}(y_5-y_a)^2\\\\ y_5 = f(z_5)\\\\ z_5 = w_{53} * y_3 + w_{54} * y_4 \\end{cases} $$\n$$ \\begin{align} \\Delta w_{53} \u0026amp;= \\frac{\\partial E}{\\partial w_{53}} \\\\ \u0026amp;= \\frac{\\partial E}{\\partial y_{5}} \\frac{\\partial y_5}{\\partial z_5} \\frac{\\partial z_5}{\\partial w_{53}} \\end{align} $$","keywords":["NN","Python"],"articleBody":"反向传播 反向传播（英语：Backpropagation，意为误差反向传播，缩写为BP）是对多层人工神经网络进行梯度下降的算法，也就是用链式法则以网络每层的权重为变数计算损失函数的梯度，以更新权重来最小化损失函数。\n简单例子计算 符号 $ w_{ij} $ 权重 $ z_i $ 输入 $ y_i $ 输出 $ E = \\frac{1}{2}(y_p-y_a)^2$ 损失 $ f(x) = \\frac{1}{1+e^{-x}}$ 激活函数 例如更新$w_{53}$\n主要思想就是我们无法找到$E$和$w_{53}$的直接关系，所以使用链式求导法则来间接求梯度： $$ w_{53}(new) = w_{53}(old) - \\Delta w_{53} $$\n$$ \\begin{cases} E = \\frac{1}{2}(y_5-y_a)^2\\\\ y_5 = f(z_5)\\\\ z_5 = w_{53} * y_3 + w_{54} * y_4 \\end{cases} $$\n$$ \\begin{align} \\Delta w_{53} \u0026= \\frac{\\partial E}{\\partial w_{53}} \\\\ \u0026= \\frac{\\partial E}{\\partial y_{5}} \\frac{\\partial y_5}{\\partial z_5} \\frac{\\partial z_5}{\\partial w_{53}} \\end{align} $$\n代码实现 from math import exp, sqrt def f(x): \"\"\"returns sigmoid(x)\"\"\" return 1 / (1 + exp(-x)) def d_f(x): \"\"\"return d(sigmoid(x))/dx\"\"\" return f(x) * (1 - f(x)) def E(yp, ya): \"\"\"return the error in squre\"\"\" return 1/2*(yp-ya)**2 def d_E(yp, ya): \"\"\"return dE/d(yp)\"\"\" return yp - ya ya = 0.5 z = {1: 0.35, 2: 0.9, 3: 0.0, 4: 0.0, 5: 0.0} w = {(1, 3): 0.1, (2, 3): 0.8, (1, 4): 0.4, (2, 4): 0.6, (3, 5): 0.3, (4, 5): 0.9} y = {i: 0.0 for i in range(1, 6)} s = {(1, 3): 0.0, (2, 3): 0.0, (1, 4): 0.0, (2, 4): 0.0, (3, 5): 0.0, (4, 5): 0.0} def forward(): \"\"\"正向计算\"\"\" y[1], y[2] = z[1], z[2] z[3], z[4] = w[1, 3] * y[1] + w[2, 3] * \\ y[2], w[1, 4] * y[1] + w[2, 4] * y[2] y[3], y[4] = f(z[3]), f(z[4]) z[5] = w[3, 5] * y[3] + w[4, 5] * y[4] y[5] = f(z[5]) e = E(y[5], ya) print(f'yp = {y[5]}, Error = {e}') return e def update(n, g): \"\"\"update weights\"\"\" w[n] -= g def back(): \"\"\"back propagation\"\"\" g = d_E(y[5], ya) * d_f(z[5]) * y[3] update((3, 5), g) g = d_E(y[5], ya) * d_f(z[5]) * y[4] update((4, 5), g) g = d_E(y[5], ya) * d_f(z[5]) * w[3, 5] * d_f(z[3]) * y[1] update((1, 3), g) g = d_E(y[5], ya) * d_f(z[5]) * w[3, 5] * d_f(z[3]) * y[2] update((2, 3), g) g = d_E(y[5], ya) * d_f(z[5]) * w[4, 5] * d_f(z[4]) * y[1] update((1, 4), g) g = d_E(y[5], ya) * d_f(z[5]) * w[4, 5] * d_f(z[4]) * y[2] update((2, 4), g) if __name__ == '__main__': step = 1 while True: print(f'step = {step}:', end=' ') if forward() \u003c 0.0000001: break step += 1 back() 运行代码，发现迭代111次后，损失才达到预期。\n➜ python3 main.py step = 1: yp = 0.6902834929076443, Error = 0.01810390383656677 step = 2: yp = 0.6820312027460466, Error = 0.016567679386586154 step = 3: yp = 0.6739592936119999, Error = 0.015130917916992996 step = 4: yp = 0.6660860653430867, Error = 0.013792290550574028 ... ... ... step = 110: yp = 0.500455314229855, Error = 1.036555239542297e-07 step = 111: yp = 0.5004302844701667, Error = 9.2572362633313e-08 动量法优化 def update(n, g): \"\"\"update weights\"\"\" lr = 0.1 beta = 0.999 epsilon = 0.01 s[n] = beta * s[n] + (1 - beta) * g**2 w[n] -= lr / (sqrt(s[n]) + epsilon) * g 代码如上，使用动量法优化后，仅迭代11步损失就达到了预期。\n➜ python3 main.py step = 1: yp = 0.6902834929076443, Error = 0.01810390383656677 step = 2: yp = 0.6118790538896405, Error = 0.006258461349620539 step = 3: yp = 0.5593494607066376, Error = 0.0017611792430843605 step = 4: yp = 0.5301730589054645, Error = 0.00045520674185631563 step = 5: yp = 0.5151484953395415, Error = 0.00011473845552605596 step = 6: yp = 0.5075810359788381, Error = 2.873605325621872e-05 step = 7: yp = 0.5037909668833773, Error = 7.185714955431785e-06 step = 8: yp = 0.5018953359787233, Error = 1.7961492361214424e-06 step = 9: yp = 0.5009475298860605, Error = 4.48906442488917e-07 step = 10: yp = 0.5004736747645289, Error = 1.1218389127573745e-07 step = 11: yp = 0.5002367820786155, Error = 2.803287637675012e-08 References https://zh.m.wikipedia.org/zh-cn/%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%E7%AE%97%E6%B3%95\n","wordCount":"568","inLanguage":"en","datePublished":"2022-10-18T21:52:39+08:00","dateModified":"2022-10-18T21:52:39+08:00","author":{"@type":"Person","name":"fffzlfk"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://fffzlfk.github.io/posts/%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD/"},"publisher":{"@type":"Organization","name":"fffzlfk's Blog","logo":{"@type":"ImageObject","url":"https://fffzlfk.github.io/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://fffzlfk.github.io accesskey=h title="fffzlfk's Blog (Alt + H)"><img src=https://fffzlfk.github.io/android-chrome-512x512.png alt aria-label=logo height=35>fffzlfk's Blog</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://github.com/fffzlfk title=GitHub><span>GitHub</span>&nbsp;<svg fill="none" shape-rendering="geometricPrecision" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12"><path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"/><path d="M15 3h6v6"/><path d="M10 14 21 3"/></svg></a></li><li><a href=https://fffzlfk.github.io/tags/ title=Tags><span>Tags</span></a></li><li><a href=https://fffzlfk.github.io/archives title=Archive><span>Archive</span></a></li><li><a href=https://fffzlfk.github.io/about/ title=About><span>About</span></a></li><li><a href=https://fffzlfk.github.io/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li><li><a href=https://travellings.link/ title=Travellings><span>Travellings</span>&nbsp;<svg fill="none" shape-rendering="geometricPrecision" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12"><path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"/><path d="M15 3h6v6"/><path d="M10 14 21 3"/></svg></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://fffzlfk.github.io>Home</a>&nbsp;»&nbsp;<a href=https://fffzlfk.github.io/posts/>Posts</a></div><h1 class=post-title>反向传播</h1><div class=post-meta><span title='2022-10-18 21:52:39 +0800 +0800'>October 18, 2022</span>&nbsp;·&nbsp;3 min&nbsp;·&nbsp;fffzlfk&nbsp;|&nbsp;<a href=https://github.com/fffzlfk/fffzlfk.github.io/blob/master/content/posts/%e5%8f%8d%e5%90%91%e4%bc%a0%e6%92%ad.md rel="noopener noreferrer" target=_blank>Suggest Changes</a></div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#%e5%8f%8d%e5%90%91%e4%bc%a0%e6%92%ad aria-label=反向传播>反向传播</a></li><li><a href=#%e7%ae%80%e5%8d%95%e4%be%8b%e5%ad%90%e8%ae%a1%e7%ae%97 aria-label=简单例子计算>简单例子计算</a><ul><li><a href=#%e4%bb%a3%e7%a0%81%e5%ae%9e%e7%8e%b0 aria-label=代码实现>代码实现</a></li><li><a href=#%e5%8a%a8%e9%87%8f%e6%b3%95%e4%bc%98%e5%8c%96 aria-label=动量法优化>动量法优化</a></li></ul></li><li><a href=#references aria-label=References>References</a></li></ul></div></details></div><div class=post-content><h2 id=反向传播>反向传播<a hidden class=anchor aria-hidden=true href=#反向传播>#</a></h2><p>反向传播（英语：Backpropagation，意为误差反向传播，缩写为BP）是对多层人工神经网络进行梯度下降的算法，也就是用链式法则以网络每层的权重为变数计算损失函数的梯度，以更新权重来最小化损失函数。</p><h2 id=简单例子计算>简单例子计算<a hidden class=anchor aria-hidden=true href=#简单例子计算>#</a></h2><p><div class=render-image><img loading=lazy src=https://p0.meituan.net/dpplatform/0102258668e345eee83a8459eaa8b95528740.png alt></div></p><table><thead><tr><th>符号</th><th></th></tr></thead><tbody><tr><td>$ w_{ij} $</td><td>权重</td></tr><tr><td>$ z_i $</td><td>输入</td></tr><tr><td>$ y_i $</td><td>输出</td></tr><tr><td>$ E = \frac{1}{2}(y_p-y_a)^2$</td><td>损失</td></tr><tr><td>$ f(x) = \frac{1}{1+e^{-x}}$</td><td>激活函数</td></tr></tbody></table><p>例如更新$w_{53}$</p><p>主要思想就是我们无法找到$E$和$w_{53}$的直接关系，所以使用链式求导法则来间接求梯度：
$$
w_{53}(new) = w_{53}(old) - \Delta w_{53}
$$</p><p>$$
\begin{cases}
E = \frac{1}{2}(y_5-y_a)^2\\
y_5 = f(z_5)\\
z_5 = w_{53} * y_3 + w_{54} * y_4
\end{cases}
$$</p><p>$$
\begin{align}
\Delta w_{53} &= \frac{\partial E}{\partial w_{53}} \\
&= \frac{\partial E}{\partial y_{5}} \frac{\partial y_5}{\partial z_5} \frac{\partial z_5}{\partial w_{53}}
\end{align}
$$</p><h3 id=代码实现>代码实现<a hidden class=anchor aria-hidden=true href=#代码实现>#</a></h3><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>from</span> math <span style=color:#f92672>import</span> exp, sqrt
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>f</span>(x):
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;&#34;&#34;returns sigmoid(x)&#34;&#34;&#34;</span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> <span style=color:#ae81ff>1</span> <span style=color:#f92672>/</span> (<span style=color:#ae81ff>1</span> <span style=color:#f92672>+</span> exp(<span style=color:#f92672>-</span>x))
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>d_f</span>(x):
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;&#34;&#34;return d(sigmoid(x))/dx&#34;&#34;&#34;</span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> f(x) <span style=color:#f92672>*</span> (<span style=color:#ae81ff>1</span> <span style=color:#f92672>-</span> f(x))
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>E</span>(yp, ya):
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;&#34;&#34;return the error in squre&#34;&#34;&#34;</span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> <span style=color:#ae81ff>1</span><span style=color:#f92672>/</span><span style=color:#ae81ff>2</span><span style=color:#f92672>*</span>(yp<span style=color:#f92672>-</span>ya)<span style=color:#f92672>**</span><span style=color:#ae81ff>2</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>d_E</span>(yp, ya):
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;&#34;&#34;return dE/d(yp)&#34;&#34;&#34;</span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> yp <span style=color:#f92672>-</span> ya
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>ya <span style=color:#f92672>=</span> <span style=color:#ae81ff>0.5</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>z <span style=color:#f92672>=</span> {<span style=color:#ae81ff>1</span>: <span style=color:#ae81ff>0.35</span>, <span style=color:#ae81ff>2</span>: <span style=color:#ae81ff>0.9</span>, <span style=color:#ae81ff>3</span>: <span style=color:#ae81ff>0.0</span>, <span style=color:#ae81ff>4</span>: <span style=color:#ae81ff>0.0</span>, <span style=color:#ae81ff>5</span>: <span style=color:#ae81ff>0.0</span>}
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>w <span style=color:#f92672>=</span> {(<span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>3</span>): <span style=color:#ae81ff>0.1</span>, (<span style=color:#ae81ff>2</span>, <span style=color:#ae81ff>3</span>): <span style=color:#ae81ff>0.8</span>, (<span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>4</span>): <span style=color:#ae81ff>0.4</span>,
</span></span><span style=display:flex><span>     (<span style=color:#ae81ff>2</span>, <span style=color:#ae81ff>4</span>): <span style=color:#ae81ff>0.6</span>, (<span style=color:#ae81ff>3</span>, <span style=color:#ae81ff>5</span>): <span style=color:#ae81ff>0.3</span>, (<span style=color:#ae81ff>4</span>, <span style=color:#ae81ff>5</span>): <span style=color:#ae81ff>0.9</span>}
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>y <span style=color:#f92672>=</span> {i: <span style=color:#ae81ff>0.0</span> <span style=color:#66d9ef>for</span> i <span style=color:#f92672>in</span> range(<span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>6</span>)}
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>s <span style=color:#f92672>=</span> {(<span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>3</span>): <span style=color:#ae81ff>0.0</span>, (<span style=color:#ae81ff>2</span>, <span style=color:#ae81ff>3</span>): <span style=color:#ae81ff>0.0</span>, (<span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>4</span>): <span style=color:#ae81ff>0.0</span>,
</span></span><span style=display:flex><span>     (<span style=color:#ae81ff>2</span>, <span style=color:#ae81ff>4</span>): <span style=color:#ae81ff>0.0</span>, (<span style=color:#ae81ff>3</span>, <span style=color:#ae81ff>5</span>): <span style=color:#ae81ff>0.0</span>, (<span style=color:#ae81ff>4</span>, <span style=color:#ae81ff>5</span>): <span style=color:#ae81ff>0.0</span>}
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>forward</span>():
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;&#34;&#34;正向计算&#34;&#34;&#34;</span>
</span></span><span style=display:flex><span>    y[<span style=color:#ae81ff>1</span>], y[<span style=color:#ae81ff>2</span>] <span style=color:#f92672>=</span> z[<span style=color:#ae81ff>1</span>], z[<span style=color:#ae81ff>2</span>]
</span></span><span style=display:flex><span>    z[<span style=color:#ae81ff>3</span>], z[<span style=color:#ae81ff>4</span>] <span style=color:#f92672>=</span> w[<span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>3</span>] <span style=color:#f92672>*</span> y[<span style=color:#ae81ff>1</span>] <span style=color:#f92672>+</span> w[<span style=color:#ae81ff>2</span>, <span style=color:#ae81ff>3</span>] <span style=color:#f92672>*</span> \
</span></span><span style=display:flex><span>        y[<span style=color:#ae81ff>2</span>], w[<span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>4</span>] <span style=color:#f92672>*</span> y[<span style=color:#ae81ff>1</span>] <span style=color:#f92672>+</span> w[<span style=color:#ae81ff>2</span>, <span style=color:#ae81ff>4</span>] <span style=color:#f92672>*</span> y[<span style=color:#ae81ff>2</span>]
</span></span><span style=display:flex><span>    y[<span style=color:#ae81ff>3</span>], y[<span style=color:#ae81ff>4</span>] <span style=color:#f92672>=</span> f(z[<span style=color:#ae81ff>3</span>]), f(z[<span style=color:#ae81ff>4</span>])
</span></span><span style=display:flex><span>    z[<span style=color:#ae81ff>5</span>] <span style=color:#f92672>=</span> w[<span style=color:#ae81ff>3</span>, <span style=color:#ae81ff>5</span>] <span style=color:#f92672>*</span> y[<span style=color:#ae81ff>3</span>] <span style=color:#f92672>+</span> w[<span style=color:#ae81ff>4</span>, <span style=color:#ae81ff>5</span>] <span style=color:#f92672>*</span> y[<span style=color:#ae81ff>4</span>]
</span></span><span style=display:flex><span>    y[<span style=color:#ae81ff>5</span>] <span style=color:#f92672>=</span> f(z[<span style=color:#ae81ff>5</span>])
</span></span><span style=display:flex><span>    e <span style=color:#f92672>=</span> E(y[<span style=color:#ae81ff>5</span>], ya)
</span></span><span style=display:flex><span>    print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#39;yp = </span><span style=color:#e6db74>{</span>y[<span style=color:#ae81ff>5</span>]<span style=color:#e6db74>}</span><span style=color:#e6db74>, Error = </span><span style=color:#e6db74>{</span>e<span style=color:#e6db74>}</span><span style=color:#e6db74>&#39;</span>)
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> e
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>update</span>(n, g):
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;&#34;&#34;update weights&#34;&#34;&#34;</span>
</span></span><span style=display:flex><span>    w[n] <span style=color:#f92672>-=</span> g
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>back</span>():
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;&#34;&#34;back propagation&#34;&#34;&#34;</span>
</span></span><span style=display:flex><span>    g <span style=color:#f92672>=</span> d_E(y[<span style=color:#ae81ff>5</span>], ya) <span style=color:#f92672>*</span> d_f(z[<span style=color:#ae81ff>5</span>]) <span style=color:#f92672>*</span> y[<span style=color:#ae81ff>3</span>]
</span></span><span style=display:flex><span>    update((<span style=color:#ae81ff>3</span>, <span style=color:#ae81ff>5</span>), g)
</span></span><span style=display:flex><span>    g <span style=color:#f92672>=</span> d_E(y[<span style=color:#ae81ff>5</span>], ya) <span style=color:#f92672>*</span> d_f(z[<span style=color:#ae81ff>5</span>]) <span style=color:#f92672>*</span> y[<span style=color:#ae81ff>4</span>]
</span></span><span style=display:flex><span>    update((<span style=color:#ae81ff>4</span>, <span style=color:#ae81ff>5</span>), g)
</span></span><span style=display:flex><span>    g <span style=color:#f92672>=</span> d_E(y[<span style=color:#ae81ff>5</span>], ya) <span style=color:#f92672>*</span> d_f(z[<span style=color:#ae81ff>5</span>]) <span style=color:#f92672>*</span> w[<span style=color:#ae81ff>3</span>, <span style=color:#ae81ff>5</span>] <span style=color:#f92672>*</span> d_f(z[<span style=color:#ae81ff>3</span>]) <span style=color:#f92672>*</span> y[<span style=color:#ae81ff>1</span>]
</span></span><span style=display:flex><span>    update((<span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>3</span>), g)
</span></span><span style=display:flex><span>    g <span style=color:#f92672>=</span> d_E(y[<span style=color:#ae81ff>5</span>], ya) <span style=color:#f92672>*</span> d_f(z[<span style=color:#ae81ff>5</span>]) <span style=color:#f92672>*</span> w[<span style=color:#ae81ff>3</span>, <span style=color:#ae81ff>5</span>] <span style=color:#f92672>*</span> d_f(z[<span style=color:#ae81ff>3</span>]) <span style=color:#f92672>*</span> y[<span style=color:#ae81ff>2</span>]
</span></span><span style=display:flex><span>    update((<span style=color:#ae81ff>2</span>, <span style=color:#ae81ff>3</span>), g)
</span></span><span style=display:flex><span>    g <span style=color:#f92672>=</span> d_E(y[<span style=color:#ae81ff>5</span>], ya) <span style=color:#f92672>*</span> d_f(z[<span style=color:#ae81ff>5</span>]) <span style=color:#f92672>*</span> w[<span style=color:#ae81ff>4</span>, <span style=color:#ae81ff>5</span>] <span style=color:#f92672>*</span> d_f(z[<span style=color:#ae81ff>4</span>]) <span style=color:#f92672>*</span> y[<span style=color:#ae81ff>1</span>]
</span></span><span style=display:flex><span>    update((<span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>4</span>), g)
</span></span><span style=display:flex><span>    g <span style=color:#f92672>=</span> d_E(y[<span style=color:#ae81ff>5</span>], ya) <span style=color:#f92672>*</span> d_f(z[<span style=color:#ae81ff>5</span>]) <span style=color:#f92672>*</span> w[<span style=color:#ae81ff>4</span>, <span style=color:#ae81ff>5</span>] <span style=color:#f92672>*</span> d_f(z[<span style=color:#ae81ff>4</span>]) <span style=color:#f92672>*</span> y[<span style=color:#ae81ff>2</span>]
</span></span><span style=display:flex><span>    update((<span style=color:#ae81ff>2</span>, <span style=color:#ae81ff>4</span>), g)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>if</span> __name__ <span style=color:#f92672>==</span> <span style=color:#e6db74>&#39;__main__&#39;</span>:
</span></span><span style=display:flex><span>    step <span style=color:#f92672>=</span> <span style=color:#ae81ff>1</span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>while</span> <span style=color:#66d9ef>True</span>:
</span></span><span style=display:flex><span>        print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#39;step = </span><span style=color:#e6db74>{</span>step<span style=color:#e6db74>}</span><span style=color:#e6db74>:&#39;</span>, end<span style=color:#f92672>=</span><span style=color:#e6db74>&#39; &#39;</span>)
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>if</span> forward() <span style=color:#f92672>&lt;</span> <span style=color:#ae81ff>0.0000001</span>:
</span></span><span style=display:flex><span>            <span style=color:#66d9ef>break</span>
</span></span><span style=display:flex><span>        step <span style=color:#f92672>+=</span> <span style=color:#ae81ff>1</span>
</span></span><span style=display:flex><span>        back()
</span></span></code></pre></div><p>运行代码，发现迭代111次后，损失才达到预期。</p><pre tabindex=0><code class=language-terminal data-lang=terminal>➜ python3 main.py
step = 1: yp = 0.6902834929076443, Error = 0.01810390383656677
step = 2: yp = 0.6820312027460466, Error = 0.016567679386586154
step = 3: yp = 0.6739592936119999, Error = 0.015130917916992996
step = 4: yp = 0.6660860653430867, Error = 0.013792290550574028
...
...
...
step = 110: yp = 0.500455314229855, Error = 1.036555239542297e-07
step = 111: yp = 0.5004302844701667, Error = 9.2572362633313e-08
</code></pre><h3 id=动量法优化>动量法优化<a hidden class=anchor aria-hidden=true href=#动量法优化>#</a></h3><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>update</span>(n, g):
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;&#34;&#34;update weights&#34;&#34;&#34;</span>
</span></span><span style=display:flex><span>    lr <span style=color:#f92672>=</span> <span style=color:#ae81ff>0.1</span>
</span></span><span style=display:flex><span>    beta <span style=color:#f92672>=</span> <span style=color:#ae81ff>0.999</span>
</span></span><span style=display:flex><span>    epsilon <span style=color:#f92672>=</span> <span style=color:#ae81ff>0.01</span>
</span></span><span style=display:flex><span>    s[n] <span style=color:#f92672>=</span> beta <span style=color:#f92672>*</span> s[n] <span style=color:#f92672>+</span> (<span style=color:#ae81ff>1</span> <span style=color:#f92672>-</span> beta) <span style=color:#f92672>*</span> g<span style=color:#f92672>**</span><span style=color:#ae81ff>2</span>
</span></span><span style=display:flex><span>    w[n] <span style=color:#f92672>-=</span> lr <span style=color:#f92672>/</span> (sqrt(s[n]) <span style=color:#f92672>+</span> epsilon) <span style=color:#f92672>*</span> g
</span></span></code></pre></div><p>代码如上，使用动量法优化后，仅迭代11步损失就达到了预期。</p><pre tabindex=0><code class=language-terminal data-lang=terminal>➜ python3 main.py
step = 1: yp = 0.6902834929076443, Error = 0.01810390383656677
step = 2: yp = 0.6118790538896405, Error = 0.006258461349620539
step = 3: yp = 0.5593494607066376, Error = 0.0017611792430843605
step = 4: yp = 0.5301730589054645, Error = 0.00045520674185631563
step = 5: yp = 0.5151484953395415, Error = 0.00011473845552605596
step = 6: yp = 0.5075810359788381, Error = 2.873605325621872e-05
step = 7: yp = 0.5037909668833773, Error = 7.185714955431785e-06
step = 8: yp = 0.5018953359787233, Error = 1.7961492361214424e-06
step = 9: yp = 0.5009475298860605, Error = 4.48906442488917e-07
step = 10: yp = 0.5004736747645289, Error = 1.1218389127573745e-07
step = 11: yp = 0.5002367820786155, Error = 2.803287637675012e-08
</code></pre><h2 id=references>References<a hidden class=anchor aria-hidden=true href=#references>#</a></h2><p><a href=https://zh.m.wikipedia.org/zh-cn/%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%E7%AE%97%E6%B3%95>https://zh.m.wikipedia.org/zh-cn/%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%E7%AE%97%E6%B3%95</a></p></div><footer class=post-footer><ul class=post-tags><li><a href=https://fffzlfk.github.io/tags/nn/>NN</a></li><li><a href=https://fffzlfk.github.io/tags/python/>Python</a></li></ul><nav class=paginav><a class=next href=https://fffzlfk.github.io/posts/%E7%BB%84%E5%90%88%E6%95%B0%E5%AD%A6%E7%AC%94%E8%AE%B0/><span class=title>Next »</span><br><span>组合数学笔记</span></a></nav></footer><div id=disqus_thread></div><script type=application/javascript>window.disqus_config=function(){},function(){if(["localhost","127.0.0.1"].indexOf(window.location.hostname)!=-1){document.getElementById("disqus_thread").innerHTML="Disqus comments not available by default when the website is previewed locally.";return}var t=document,e=t.createElement("script");e.async=!0,e.src="//https-fffzlfk-github-io.disqus.com/embed.js",e.setAttribute("data-timestamp",+new Date),(t.head||t.body).appendChild(e)}()</script><noscript>Please enable JavaScript to view the <a href=https://disqus.com/?ref_noscript>comments powered by Disqus.</a></noscript><a href=https://disqus.com class=dsq-brlink>comments powered by <span class=logo-disqus>Disqus</span></a></article></main><footer class=footer><span>&copy; 2022 <a href=https://fffzlfk.github.io>fffzlfk's Blog</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>