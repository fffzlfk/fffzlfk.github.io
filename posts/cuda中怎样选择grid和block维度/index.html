<!doctype html><html class="not-ready lg:text-base" style=--bg:#faf8f1 lang=zh-cn dir=ltr><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><title>CUDA中怎样选择GRID和BLOCK维度 - fffzlfk's Blog</title>
<meta name=theme-color><meta name=description content='硬件限制
这是容易量化的方面。目前CUDA编程指南的附录F列出了一些硬件限制，这些限制限制了内核启动时每块可以有多少个线程。如果你超过了这些限制，你的内核将无法运行。这些限制可以粗略地概括为：

每个区块不能超过 $512$ / $1024$ 个线程（分别是计算能力1.x或2.x及以后的计算能力
每个块的最大尺寸限制在 $[512, 512, 64]$ / $[1024, 1024, 64]$（计算能力1.x/2.x及以后的计算能力
每个块消耗的寄存器总数不能超过 $8k/16k/32k/64k/32k/64k/32k/64k$ （计算能力 $1.0,1.1/1.2,1.3/2.x-3.0/3.2/3.5-5.2/5.3/6-6.1/6.2/7.0$
每个块不能消耗超过 $16kb/48kb/96kb$ 的共享内存（计算能力 $1.x/2.x-6.2/7.0$

如果你保持在这些限制之内，任何你能成功编译的内核都会无错误地启动。
性能调教
这是需要经验的一部分。在上述的硬件约束条件下，你选择的每块线程数可以而且确实影响到硬件上运行的代码性能。每个代码的表现都是不同的，唯一真正的方法是通过仔细的基准测试和剖析来量化它。但还是那句话，非常粗略地总结一下：

每个区块的线程数应该是wrap大小的整数倍，在目前所有的硬件上都是 $32$
GPU上的每个流式多处理器必须有足够的active wraps来充分隐藏架构的的所有不同内存和指令流水线延迟，以实现最大吞吐量。这里的正确做法是尝试实现最佳的硬件占用率

CUDA内置函数
上述指出了块的大小是如何影响性能的，并提出了一种基于占用率最大化的通用启发式选择方法。在不想提供选择块大小的标准的情况下，值得一提的是，CUDA 6.5+包括几个新的运行时函数来帮助占用率的计算和启动配置1。
其中一个有用的函数是cudaOccupancyMaxPotentialBlockSize，它启发式地计算了一个能达到最佳占用率的块大小。该函数提供的值可以作为手动优化参数的起点。下面是一个例子：
/************************/
/* TEST KERNEL FUNCTION */
/************************/
__global__ void MyKernel(int *a, int *b, int *c, int N) 
{ 
    int idx = threadIdx.x + blockIdx.x * blockDim.x; 

    if (idx < N) { c[idx] = a[idx] + b[idx]; } 
} 

/********/
/* MAIN */
/********/
void main() 
{ 
    const int N = 1000000;

    int blockSize;      // The launch configurator returned block size 
    int minGridSize;    // The minimum grid size needed to achieve the maximum occupancy for a full device launch 
    int gridSize;       // The actual grid size needed, based on input size 

    int* h_vec1 = (int*) malloc(N*sizeof(int));
    int* h_vec2 = (int*) malloc(N*sizeof(int));
    int* h_vec3 = (int*) malloc(N*sizeof(int));
    int* h_vec4 = (int*) malloc(N*sizeof(int));

    int* d_vec1; cudaMalloc((void**)&amp;d_vec1, N*sizeof(int));
    int* d_vec2; cudaMalloc((void**)&amp;d_vec2, N*sizeof(int));
    int* d_vec3; cudaMalloc((void**)&amp;d_vec3, N*sizeof(int));

    for (int i=0; i<N; i++) {
        h_vec1[i] = 10;
        h_vec2[i] = 20;
        h_vec4[i] = h_vec1[i] + h_vec2[i];
    }

    cudaMemcpy(d_vec1, h_vec1, N*sizeof(int), cudaMemcpyHostToDevice);
    cudaMemcpy(d_vec2, h_vec2, N*sizeof(int), cudaMemcpyHostToDevice);

    float time;
    cudaEvent_t start, stop;
    cudaEventCreate(&amp;start);
    cudaEventCreate(&amp;stop);
    cudaEventRecord(start, 0);

    cudaOccupancyMaxPotentialBlockSize(&amp;minGridSize, &amp;blockSize, MyKernel, 0, N); 

    // Round up according to array size 
    gridSize = (N + blockSize - 1) / blockSize; 

    cudaEventRecord(stop, 0);
    cudaEventSynchronize(stop);
    cudaEventElapsedTime(&amp;time, start, stop);
    printf("Occupancy calculator elapsed time:  %3.3f ms \n", time);

    cudaEventRecord(start, 0);

    MyKernel<<<gridSize, blockSize>>>(d_vec1, d_vec2, d_vec3, N); 

    cudaEventRecord(stop, 0);
    cudaEventSynchronize(stop);
    cudaEventElapsedTime(&amp;time, start, stop);
    printf("Kernel elapsed time:  %3.3f ms \n", time);

    printf("Blocksize %i\n", blockSize);

    cudaMemcpy(h_vec3, d_vec3, N*sizeof(int), cudaMemcpyDeviceToHost);

    for (int i=0; i<N; i++) {
        if (h_vec3[i] != h_vec4[i]) { printf("Error at i = %i! Host = %i; Device = %i\n", i, h_vec4[i], h_vec3[i]); return; };
    }

    printf("Test passed\n");
}
cudaOccupancyMaxPotentialBlockSize定义在cuda_runtime.h文件中：'><meta name=author content="fffzlfk"><link rel="preload stylesheet" as=style href=https://fffzlfk.github.io/main.min.css><link rel=preload as=image href=https://fffzlfk.github.io/theme.svg><link rel=preload as=image href="https://avatars.githubusercontent.com/u/44939690?v=4"><link rel=preload as=image href=https://fffzlfk.github.io/github.svg><link rel=preload as=image href=https://fffzlfk.github.io/instagram.svg><link rel=preload as=image href=https://fffzlfk.github.io/rss.svg><link rel=stylesheet href=/css/fonts.css><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.7/dist/katex.min.css integrity=sha384-3UiQGuEI4TTMaFmGIZumfRPtfKQ3trwQE2JgosJxCnGmQpL/lJdjpcHkaaFwHlcI crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.7/dist/katex.min.js integrity=sha384-G0zcxDFp5LWZtDuRMnBkk3EphCK1lhEf4UEyEM693ka574TZGwo4IWwS6QLzM/2t crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.7/dist/contrib/auto-render.min.js integrity=sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05 crossorigin=anonymous></script><script>document.addEventListener("DOMContentLoaded",()=>renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}],throwOnError:!1}))</script><link rel=icon href=https://fffzlfk.github.io/favicon.ico><link rel=apple-touch-icon href=https://fffzlfk.github.io/apple-touch-icon.png><meta name=generator content="Hugo 0.147.4"><meta itemprop=name content="CUDA中怎样选择GRID和BLOCK维度"><meta itemprop=description content='硬件限制 这是容易量化的方面。目前CUDA编程指南的附录F列出了一些硬件限制，这些限制限制了内核启动时每块可以有多少个线程。如果你超过了这些限制，你的内核将无法运行。这些限制可以粗略地概括为：
每个区块不能超过 $512$ / $1024$ 个线程（分别是计算能力1.x或2.x及以后的计算能力 每个块的最大尺寸限制在 $[512, 512, 64]$ / $[1024, 1024, 64]$（计算能力1.x/2.x及以后的计算能力 每个块消耗的寄存器总数不能超过 $8k/16k/32k/64k/32k/64k/32k/64k$ （计算能力 $1.0,1.1/1.2,1.3/2.x-3.0/3.2/3.5-5.2/5.3/6-6.1/6.2/7.0$ 每个块不能消耗超过 $16kb/48kb/96kb$ 的共享内存（计算能力 $1.x/2.x-6.2/7.0$ 如果你保持在这些限制之内，任何你能成功编译的内核都会无错误地启动。
性能调教 这是需要经验的一部分。在上述的硬件约束条件下，你选择的每块线程数可以而且确实影响到硬件上运行的代码性能。每个代码的表现都是不同的，唯一真正的方法是通过仔细的基准测试和剖析来量化它。但还是那句话，非常粗略地总结一下：
每个区块的线程数应该是wrap大小的整数倍，在目前所有的硬件上都是 $32$ GPU上的每个流式多处理器必须有足够的active wraps来充分隐藏架构的的所有不同内存和指令流水线延迟，以实现最大吞吐量。这里的正确做法是尝试实现最佳的硬件占用率 CUDA内置函数 上述指出了块的大小是如何影响性能的，并提出了一种基于占用率最大化的通用启发式选择方法。在不想提供选择块大小的标准的情况下，值得一提的是，CUDA 6.5+包括几个新的运行时函数来帮助占用率的计算和启动配置1。
其中一个有用的函数是cudaOccupancyMaxPotentialBlockSize，它启发式地计算了一个能达到最佳占用率的块大小。该函数提供的值可以作为手动优化参数的起点。下面是一个例子：
/************************/ /* TEST KERNEL FUNCTION */ /************************/ __global__ void MyKernel(int *a, int *b, int *c, int N) { int idx = threadIdx.x + blockIdx.x * blockDim.x; if (idx < N) { c[idx] = a[idx] + b[idx]; } } /********/ /* MAIN */ /********/ void main() { const int N = 1000000; int blockSize; // The launch configurator returned block size int minGridSize; // The minimum grid size needed to achieve the maximum occupancy for a full device launch int gridSize; // The actual grid size needed, based on input size int* h_vec1 = (int*) malloc(N*sizeof(int)); int* h_vec2 = (int*) malloc(N*sizeof(int)); int* h_vec3 = (int*) malloc(N*sizeof(int)); int* h_vec4 = (int*) malloc(N*sizeof(int)); int* d_vec1; cudaMalloc((void**)&amp;d_vec1, N*sizeof(int)); int* d_vec2; cudaMalloc((void**)&amp;d_vec2, N*sizeof(int)); int* d_vec3; cudaMalloc((void**)&amp;d_vec3, N*sizeof(int)); for (int i=0; i<N; i++) { h_vec1[i] = 10; h_vec2[i] = 20; h_vec4[i] = h_vec1[i] + h_vec2[i]; } cudaMemcpy(d_vec1, h_vec1, N*sizeof(int), cudaMemcpyHostToDevice); cudaMemcpy(d_vec2, h_vec2, N*sizeof(int), cudaMemcpyHostToDevice); float time; cudaEvent_t start, stop; cudaEventCreate(&amp;start); cudaEventCreate(&amp;stop); cudaEventRecord(start, 0); cudaOccupancyMaxPotentialBlockSize(&amp;minGridSize, &amp;blockSize, MyKernel, 0, N); // Round up according to array size gridSize = (N + blockSize - 1) / blockSize; cudaEventRecord(stop, 0); cudaEventSynchronize(stop); cudaEventElapsedTime(&amp;time, start, stop); printf("Occupancy calculator elapsed time: %3.3f ms \n", time); cudaEventRecord(start, 0); MyKernel<<<gridSize, blockSize>>>(d_vec1, d_vec2, d_vec3, N); cudaEventRecord(stop, 0); cudaEventSynchronize(stop); cudaEventElapsedTime(&amp;time, start, stop); printf("Kernel elapsed time: %3.3f ms \n", time); printf("Blocksize %i\n", blockSize); cudaMemcpy(h_vec3, d_vec3, N*sizeof(int), cudaMemcpyDeviceToHost); for (int i=0; i<N; i++) { if (h_vec3[i] != h_vec4[i]) { printf("Error at i = %i! Host = %i; Device = %i\n", i, h_vec4[i], h_vec3[i]); return; }; } printf("Test passed\n"); } cudaOccupancyMaxPotentialBlockSize定义在cuda_runtime.h文件中：'><meta itemprop=datePublished content="2022-03-07T16:10:36+08:00"><meta itemprop=dateModified content="2022-03-07T16:10:36+08:00"><meta itemprop=wordCount content="324"><meta itemprop=keywords content="CUDA"><meta property="og:url" content="https://fffzlfk.github.io/posts/cuda%E4%B8%AD%E6%80%8E%E6%A0%B7%E9%80%89%E6%8B%A9grid%E5%92%8Cblock%E7%BB%B4%E5%BA%A6/"><meta property="og:site_name" content="fffzlfk's Blog"><meta property="og:title" content="CUDA中怎样选择GRID和BLOCK维度"><meta property="og:description" content='硬件限制 这是容易量化的方面。目前CUDA编程指南的附录F列出了一些硬件限制，这些限制限制了内核启动时每块可以有多少个线程。如果你超过了这些限制，你的内核将无法运行。这些限制可以粗略地概括为：
每个区块不能超过 $512$ / $1024$ 个线程（分别是计算能力1.x或2.x及以后的计算能力 每个块的最大尺寸限制在 $[512, 512, 64]$ / $[1024, 1024, 64]$（计算能力1.x/2.x及以后的计算能力 每个块消耗的寄存器总数不能超过 $8k/16k/32k/64k/32k/64k/32k/64k$ （计算能力 $1.0,1.1/1.2,1.3/2.x-3.0/3.2/3.5-5.2/5.3/6-6.1/6.2/7.0$ 每个块不能消耗超过 $16kb/48kb/96kb$ 的共享内存（计算能力 $1.x/2.x-6.2/7.0$ 如果你保持在这些限制之内，任何你能成功编译的内核都会无错误地启动。
性能调教 这是需要经验的一部分。在上述的硬件约束条件下，你选择的每块线程数可以而且确实影响到硬件上运行的代码性能。每个代码的表现都是不同的，唯一真正的方法是通过仔细的基准测试和剖析来量化它。但还是那句话，非常粗略地总结一下：
每个区块的线程数应该是wrap大小的整数倍，在目前所有的硬件上都是 $32$ GPU上的每个流式多处理器必须有足够的active wraps来充分隐藏架构的的所有不同内存和指令流水线延迟，以实现最大吞吐量。这里的正确做法是尝试实现最佳的硬件占用率 CUDA内置函数 上述指出了块的大小是如何影响性能的，并提出了一种基于占用率最大化的通用启发式选择方法。在不想提供选择块大小的标准的情况下，值得一提的是，CUDA 6.5+包括几个新的运行时函数来帮助占用率的计算和启动配置1。
其中一个有用的函数是cudaOccupancyMaxPotentialBlockSize，它启发式地计算了一个能达到最佳占用率的块大小。该函数提供的值可以作为手动优化参数的起点。下面是一个例子：
/************************/ /* TEST KERNEL FUNCTION */ /************************/ __global__ void MyKernel(int *a, int *b, int *c, int N) { int idx = threadIdx.x + blockIdx.x * blockDim.x; if (idx < N) { c[idx] = a[idx] + b[idx]; } } /********/ /* MAIN */ /********/ void main() { const int N = 1000000; int blockSize; // The launch configurator returned block size int minGridSize; // The minimum grid size needed to achieve the maximum occupancy for a full device launch int gridSize; // The actual grid size needed, based on input size int* h_vec1 = (int*) malloc(N*sizeof(int)); int* h_vec2 = (int*) malloc(N*sizeof(int)); int* h_vec3 = (int*) malloc(N*sizeof(int)); int* h_vec4 = (int*) malloc(N*sizeof(int)); int* d_vec1; cudaMalloc((void**)&amp;d_vec1, N*sizeof(int)); int* d_vec2; cudaMalloc((void**)&amp;d_vec2, N*sizeof(int)); int* d_vec3; cudaMalloc((void**)&amp;d_vec3, N*sizeof(int)); for (int i=0; i<N; i++) { h_vec1[i] = 10; h_vec2[i] = 20; h_vec4[i] = h_vec1[i] + h_vec2[i]; } cudaMemcpy(d_vec1, h_vec1, N*sizeof(int), cudaMemcpyHostToDevice); cudaMemcpy(d_vec2, h_vec2, N*sizeof(int), cudaMemcpyHostToDevice); float time; cudaEvent_t start, stop; cudaEventCreate(&amp;start); cudaEventCreate(&amp;stop); cudaEventRecord(start, 0); cudaOccupancyMaxPotentialBlockSize(&amp;minGridSize, &amp;blockSize, MyKernel, 0, N); // Round up according to array size gridSize = (N + blockSize - 1) / blockSize; cudaEventRecord(stop, 0); cudaEventSynchronize(stop); cudaEventElapsedTime(&amp;time, start, stop); printf("Occupancy calculator elapsed time: %3.3f ms \n", time); cudaEventRecord(start, 0); MyKernel<<<gridSize, blockSize>>>(d_vec1, d_vec2, d_vec3, N); cudaEventRecord(stop, 0); cudaEventSynchronize(stop); cudaEventElapsedTime(&amp;time, start, stop); printf("Kernel elapsed time: %3.3f ms \n", time); printf("Blocksize %i\n", blockSize); cudaMemcpy(h_vec3, d_vec3, N*sizeof(int), cudaMemcpyDeviceToHost); for (int i=0; i<N; i++) { if (h_vec3[i] != h_vec4[i]) { printf("Error at i = %i! Host = %i; Device = %i\n", i, h_vec4[i], h_vec3[i]); return; }; } printf("Test passed\n"); } cudaOccupancyMaxPotentialBlockSize定义在cuda_runtime.h文件中：'><meta property="og:locale" content="zh_cn"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2022-03-07T16:10:36+08:00"><meta property="article:modified_time" content="2022-03-07T16:10:36+08:00"><meta property="article:tag" content="CUDA"><meta name=twitter:card content="summary"><meta name=twitter:title content="CUDA中怎样选择GRID和BLOCK维度"><meta name=twitter:description content='硬件限制 这是容易量化的方面。目前CUDA编程指南的附录F列出了一些硬件限制，这些限制限制了内核启动时每块可以有多少个线程。如果你超过了这些限制，你的内核将无法运行。这些限制可以粗略地概括为：
每个区块不能超过 $512$ / $1024$ 个线程（分别是计算能力1.x或2.x及以后的计算能力 每个块的最大尺寸限制在 $[512, 512, 64]$ / $[1024, 1024, 64]$（计算能力1.x/2.x及以后的计算能力 每个块消耗的寄存器总数不能超过 $8k/16k/32k/64k/32k/64k/32k/64k$ （计算能力 $1.0,1.1/1.2,1.3/2.x-3.0/3.2/3.5-5.2/5.3/6-6.1/6.2/7.0$ 每个块不能消耗超过 $16kb/48kb/96kb$ 的共享内存（计算能力 $1.x/2.x-6.2/7.0$ 如果你保持在这些限制之内，任何你能成功编译的内核都会无错误地启动。
性能调教 这是需要经验的一部分。在上述的硬件约束条件下，你选择的每块线程数可以而且确实影响到硬件上运行的代码性能。每个代码的表现都是不同的，唯一真正的方法是通过仔细的基准测试和剖析来量化它。但还是那句话，非常粗略地总结一下：
每个区块的线程数应该是wrap大小的整数倍，在目前所有的硬件上都是 $32$ GPU上的每个流式多处理器必须有足够的active wraps来充分隐藏架构的的所有不同内存和指令流水线延迟，以实现最大吞吐量。这里的正确做法是尝试实现最佳的硬件占用率 CUDA内置函数 上述指出了块的大小是如何影响性能的，并提出了一种基于占用率最大化的通用启发式选择方法。在不想提供选择块大小的标准的情况下，值得一提的是，CUDA 6.5+包括几个新的运行时函数来帮助占用率的计算和启动配置1。
其中一个有用的函数是cudaOccupancyMaxPotentialBlockSize，它启发式地计算了一个能达到最佳占用率的块大小。该函数提供的值可以作为手动优化参数的起点。下面是一个例子：
/************************/ /* TEST KERNEL FUNCTION */ /************************/ __global__ void MyKernel(int *a, int *b, int *c, int N) { int idx = threadIdx.x + blockIdx.x * blockDim.x; if (idx < N) { c[idx] = a[idx] + b[idx]; } } /********/ /* MAIN */ /********/ void main() { const int N = 1000000; int blockSize; // The launch configurator returned block size int minGridSize; // The minimum grid size needed to achieve the maximum occupancy for a full device launch int gridSize; // The actual grid size needed, based on input size int* h_vec1 = (int*) malloc(N*sizeof(int)); int* h_vec2 = (int*) malloc(N*sizeof(int)); int* h_vec3 = (int*) malloc(N*sizeof(int)); int* h_vec4 = (int*) malloc(N*sizeof(int)); int* d_vec1; cudaMalloc((void**)&amp;d_vec1, N*sizeof(int)); int* d_vec2; cudaMalloc((void**)&amp;d_vec2, N*sizeof(int)); int* d_vec3; cudaMalloc((void**)&amp;d_vec3, N*sizeof(int)); for (int i=0; i<N; i++) { h_vec1[i] = 10; h_vec2[i] = 20; h_vec4[i] = h_vec1[i] + h_vec2[i]; } cudaMemcpy(d_vec1, h_vec1, N*sizeof(int), cudaMemcpyHostToDevice); cudaMemcpy(d_vec2, h_vec2, N*sizeof(int), cudaMemcpyHostToDevice); float time; cudaEvent_t start, stop; cudaEventCreate(&amp;start); cudaEventCreate(&amp;stop); cudaEventRecord(start, 0); cudaOccupancyMaxPotentialBlockSize(&amp;minGridSize, &amp;blockSize, MyKernel, 0, N); // Round up according to array size gridSize = (N + blockSize - 1) / blockSize; cudaEventRecord(stop, 0); cudaEventSynchronize(stop); cudaEventElapsedTime(&amp;time, start, stop); printf("Occupancy calculator elapsed time: %3.3f ms \n", time); cudaEventRecord(start, 0); MyKernel<<<gridSize, blockSize>>>(d_vec1, d_vec2, d_vec3, N); cudaEventRecord(stop, 0); cudaEventSynchronize(stop); cudaEventElapsedTime(&amp;time, start, stop); printf("Kernel elapsed time: %3.3f ms \n", time); printf("Blocksize %i\n", blockSize); cudaMemcpy(h_vec3, d_vec3, N*sizeof(int), cudaMemcpyDeviceToHost); for (int i=0; i<N; i++) { if (h_vec3[i] != h_vec4[i]) { printf("Error at i = %i! Host = %i; Device = %i\n", i, h_vec4[i], h_vec3[i]); return; }; } printf("Test passed\n"); } cudaOccupancyMaxPotentialBlockSize定义在cuda_runtime.h文件中：'><link rel=canonical href=https://fffzlfk.github.io/posts/cuda%E4%B8%AD%E6%80%8E%E6%A0%B7%E9%80%89%E6%8B%A9grid%E5%92%8Cblock%E7%BB%B4%E5%BA%A6/></head><body class="bg-(--bg) text-black antialiased duration-200 ease-out [-webkit-tap-highlight-color:transparent] dark:text-white"><header class="mx-auto flex h-[4.5rem] max-w-(--w) px-8 whitespace-nowrap lg:justify-center"><div class="relative z-50 flex items-center ltr:mr-auto rtl:ml-auto"><a class="-translate-y-[1px] text-2xl font-medium" href=https://fffzlfk.github.io/>fffzlfk's Blog</a><div class="btn-dark text-[0px] ltr:ml-4 rtl:mr-4 h-6 w-6 shrink-0 cursor-pointer [background:url(./theme.svg)_left_center/cover_no-repeat] dark:invert dark:[background-position:right]" role=button aria-label=Dark></div></div><div class="btn-menu relative z-50 flex h-[4.5rem] w-[5rem] shrink-0 cursor-pointer flex-col items-center justify-center gap-2.5 lg:hidden ltr:-mr-8 rtl:-ml-8" role=button aria-label=Menu></div><script>const htmlClass=document.documentElement.classList;setTimeout(()=>{htmlClass.remove("not-ready")},10);const btnMenu=document.querySelector(".btn-menu");btnMenu.addEventListener("click",()=>{htmlClass.toggle("open")});const metaTheme=document.querySelector('meta[name="theme-color"]'),lightBg="#faf8f1".replace(/"/g,""),setDark=e=>{metaTheme.setAttribute("content",e?"#000":lightBg),htmlClass[e?"add":"remove"]("dark"),localStorage.setItem("dark",e)},darkScheme=window.matchMedia("(prefers-color-scheme: dark)");if(htmlClass.contains("dark"))setDark(!0);else{const e=localStorage.getItem("dark");setDark(e?e==="true":darkScheme.matches)}darkScheme.addEventListener("change",e=>{setDark(e.matches)});const btnDark=document.querySelector(".btn-dark");btnDark.addEventListener("click",()=>{setDark(localStorage.getItem("dark")!=="true")})</script><div class="nav-wrapper fixed inset-x-0 top-full z-40 flex h-full flex-col justify-center bg-(--bg) pb-16 duration-200 select-none lg:static lg:h-auto lg:flex-row lg:bg-transparent! lg:pb-0 lg:transition-none"><nav class="mt-12 flex justify-center space-x-10 lg:mt-0 lg:items-center ltr:lg:ml-14 rtl:space-x-reverse rtl:lg:mr-14 dark:invert"><a class="h-7 w-7 text-[0px] [background:var(--url)_center_center/cover_no-repeat] lg:h-6 lg:w-6" style=--url:url(./github.svg) href=https://github.com/fffzlfk target=_blank rel=me>github</a>
<a class="h-7 w-7 text-[0px] [background:var(--url)_center_center/cover_no-repeat] lg:h-6 lg:w-6" style=--url:url(./instagram.svg) href=https://instagram.com/fffzlfk target=_blank rel=me>instagram</a>
<a class="h-7 w-7 text-[0px] [background:var(--url)_center_center/cover_no-repeat] lg:h-6 lg:w-6" style=--url:url(./rss.svg) href=https://fffzlfk.github.io/index.xml target=_blank rel=alternate>rss</a></nav></div></header><main class="prose prose-neutral dark:prose-invert relative mx-auto min-h-[calc(100vh-9rem)] max-w-(--w) px-8 pt-14 pb-16"><article><header class=mb-14><h1 class="my-0! pb-2.5">CUDA中怎样选择GRID和BLOCK维度</h1><div class="text-xs antialiased opacity-60"><time>Mar 7, 2022</time></div></header><section><h2 id=硬件限制>硬件限制</h2><p>这是容易量化的方面。目前<a href=https://www.nvidia.cn/docs/IO/51635/NVIDIA_CUDA_Programming_Guide_1.1_chs.pdf>CUDA编程指南</a>的附录F列出了一些硬件限制，这些限制限制了内核启动时每块可以有多少个线程。如果你超过了这些限制，你的内核将无法运行。这些限制可以粗略地概括为：</p><ul><li>每个区块不能超过 $512$ / $1024$ 个线程（分别是计算能力<code>1.x</code>或<code>2.x</code>及以后的计算能力</li><li>每个块的最大尺寸限制在 $[512, 512, 64]$ / $[1024, 1024, 64]$（计算能力<code>1.x</code>/<code>2.x</code>及以后的计算能力</li><li>每个块消耗的寄存器总数不能超过 $8k/16k/32k/64k/32k/64k/32k/64k$ （计算能力 $1.0,1.1/1.2,1.3/2.x-3.0/3.2/3.5-5.2/5.3/6-6.1/6.2/7.0$</li><li>每个块不能消耗超过 $16kb/48kb/96kb$ 的共享内存（计算能力 $1.x/2.x-6.2/7.0$</li></ul><p>如果你保持在这些限制之内，任何你能成功编译的内核都会无错误地启动。</p><h2 id=性能调教>性能调教</h2><p>这是需要经验的一部分。在上述的硬件约束条件下，你选择的每块线程数可以而且确实影响到硬件上运行的代码性能。每个代码的表现都是不同的，唯一真正的方法是通过仔细的基准测试和剖析来量化它。但还是那句话，非常粗略地总结一下：</p><ul><li>每个区块的线程数应该是<code>wrap</code>大小的整数倍，在目前所有的硬件上都是 $32$</li><li><code>GPU</code>上的每个流式多处理器必须有足够的<code>active wraps</code>来充分隐藏架构的的所有不同内存和指令流水线延迟，以实现最大吞吐量。这里的正确做法是尝试实现最佳的硬件占用率</li></ul><h2 id=cuda内置函数>CUDA内置函数</h2><p>上述指出了块的大小是如何影响性能的，并提出了一种基于占用率最大化的通用启发式选择方法。在不想提供选择块大小的标准的情况下，值得一提的是，<code>CUDA 6.5+</code>包括几个新的运行时函数来帮助占用率的计算和启动配置<sup id=fnref:1><a href=#fn:1 class=footnote-ref role=doc-noteref>1</a></sup>。</p><p>其中一个有用的函数是<code>cudaOccupancyMaxPotentialBlockSize</code>，它启发式地计算了一个能达到最佳占用率的块大小。该函数提供的值可以作为手动优化参数的起点。下面是一个例子：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-cpp data-lang=cpp><span style=display:flex><span><span style=color:#75715e>/************************/</span>
</span></span><span style=display:flex><span><span style=color:#75715e>/* TEST KERNEL FUNCTION */</span>
</span></span><span style=display:flex><span><span style=color:#75715e>/************************/</span>
</span></span><span style=display:flex><span>__global__ <span style=color:#66d9ef>void</span> <span style=color:#a6e22e>MyKernel</span>(<span style=color:#66d9ef>int</span> <span style=color:#f92672>*</span>a, <span style=color:#66d9ef>int</span> <span style=color:#f92672>*</span>b, <span style=color:#66d9ef>int</span> <span style=color:#f92672>*</span>c, <span style=color:#66d9ef>int</span> N) 
</span></span><span style=display:flex><span>{ 
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>int</span> idx <span style=color:#f92672>=</span> threadIdx.x <span style=color:#f92672>+</span> blockIdx.x <span style=color:#f92672>*</span> blockDim.x; 
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>if</span> (idx <span style=color:#f92672>&lt;</span> N) { c[idx] <span style=color:#f92672>=</span> a[idx] <span style=color:#f92672>+</span> b[idx]; } 
</span></span><span style=display:flex><span>} 
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>/********/</span>
</span></span><span style=display:flex><span><span style=color:#75715e>/* MAIN */</span>
</span></span><span style=display:flex><span><span style=color:#75715e>/********/</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>void</span> <span style=color:#a6e22e>main</span>() 
</span></span><span style=display:flex><span>{ 
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>const</span> <span style=color:#66d9ef>int</span> N <span style=color:#f92672>=</span> <span style=color:#ae81ff>1000000</span>;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>int</span> blockSize;      <span style=color:#75715e>// The launch configurator returned block size 
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>    <span style=color:#66d9ef>int</span> minGridSize;    <span style=color:#75715e>// The minimum grid size needed to achieve the maximum occupancy for a full device launch 
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>    <span style=color:#66d9ef>int</span> gridSize;       <span style=color:#75715e>// The actual grid size needed, based on input size 
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>int</span><span style=color:#f92672>*</span> h_vec1 <span style=color:#f92672>=</span> (<span style=color:#66d9ef>int</span><span style=color:#f92672>*</span>) malloc(N<span style=color:#f92672>*</span><span style=color:#66d9ef>sizeof</span>(<span style=color:#66d9ef>int</span>));
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>int</span><span style=color:#f92672>*</span> h_vec2 <span style=color:#f92672>=</span> (<span style=color:#66d9ef>int</span><span style=color:#f92672>*</span>) malloc(N<span style=color:#f92672>*</span><span style=color:#66d9ef>sizeof</span>(<span style=color:#66d9ef>int</span>));
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>int</span><span style=color:#f92672>*</span> h_vec3 <span style=color:#f92672>=</span> (<span style=color:#66d9ef>int</span><span style=color:#f92672>*</span>) malloc(N<span style=color:#f92672>*</span><span style=color:#66d9ef>sizeof</span>(<span style=color:#66d9ef>int</span>));
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>int</span><span style=color:#f92672>*</span> h_vec4 <span style=color:#f92672>=</span> (<span style=color:#66d9ef>int</span><span style=color:#f92672>*</span>) malloc(N<span style=color:#f92672>*</span><span style=color:#66d9ef>sizeof</span>(<span style=color:#66d9ef>int</span>));
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>int</span><span style=color:#f92672>*</span> d_vec1; cudaMalloc((<span style=color:#66d9ef>void</span><span style=color:#f92672>**</span>)<span style=color:#f92672>&amp;</span>d_vec1, N<span style=color:#f92672>*</span><span style=color:#66d9ef>sizeof</span>(<span style=color:#66d9ef>int</span>));
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>int</span><span style=color:#f92672>*</span> d_vec2; cudaMalloc((<span style=color:#66d9ef>void</span><span style=color:#f92672>**</span>)<span style=color:#f92672>&amp;</span>d_vec2, N<span style=color:#f92672>*</span><span style=color:#66d9ef>sizeof</span>(<span style=color:#66d9ef>int</span>));
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>int</span><span style=color:#f92672>*</span> d_vec3; cudaMalloc((<span style=color:#66d9ef>void</span><span style=color:#f92672>**</span>)<span style=color:#f92672>&amp;</span>d_vec3, N<span style=color:#f92672>*</span><span style=color:#66d9ef>sizeof</span>(<span style=color:#66d9ef>int</span>));
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>for</span> (<span style=color:#66d9ef>int</span> i<span style=color:#f92672>=</span><span style=color:#ae81ff>0</span>; i<span style=color:#f92672>&lt;</span>N; i<span style=color:#f92672>++</span>) {
</span></span><span style=display:flex><span>        h_vec1[i] <span style=color:#f92672>=</span> <span style=color:#ae81ff>10</span>;
</span></span><span style=display:flex><span>        h_vec2[i] <span style=color:#f92672>=</span> <span style=color:#ae81ff>20</span>;
</span></span><span style=display:flex><span>        h_vec4[i] <span style=color:#f92672>=</span> h_vec1[i] <span style=color:#f92672>+</span> h_vec2[i];
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    cudaMemcpy(d_vec1, h_vec1, N<span style=color:#f92672>*</span><span style=color:#66d9ef>sizeof</span>(<span style=color:#66d9ef>int</span>), cudaMemcpyHostToDevice);
</span></span><span style=display:flex><span>    cudaMemcpy(d_vec2, h_vec2, N<span style=color:#f92672>*</span><span style=color:#66d9ef>sizeof</span>(<span style=color:#66d9ef>int</span>), cudaMemcpyHostToDevice);
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>float</span> time;
</span></span><span style=display:flex><span>    cudaEvent_t start, stop;
</span></span><span style=display:flex><span>    cudaEventCreate(<span style=color:#f92672>&amp;</span>start);
</span></span><span style=display:flex><span>    cudaEventCreate(<span style=color:#f92672>&amp;</span>stop);
</span></span><span style=display:flex><span>    cudaEventRecord(start, <span style=color:#ae81ff>0</span>);
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    cudaOccupancyMaxPotentialBlockSize(<span style=color:#f92672>&amp;</span>minGridSize, <span style=color:#f92672>&amp;</span>blockSize, MyKernel, <span style=color:#ae81ff>0</span>, N); 
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e>// Round up according to array size 
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>    gridSize <span style=color:#f92672>=</span> (N <span style=color:#f92672>+</span> blockSize <span style=color:#f92672>-</span> <span style=color:#ae81ff>1</span>) <span style=color:#f92672>/</span> blockSize; 
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    cudaEventRecord(stop, <span style=color:#ae81ff>0</span>);
</span></span><span style=display:flex><span>    cudaEventSynchronize(stop);
</span></span><span style=display:flex><span>    cudaEventElapsedTime(<span style=color:#f92672>&amp;</span>time, start, stop);
</span></span><span style=display:flex><span>    printf(<span style=color:#e6db74>&#34;Occupancy calculator elapsed time:  %3.3f ms </span><span style=color:#ae81ff>\n</span><span style=color:#e6db74>&#34;</span>, time);
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    cudaEventRecord(start, <span style=color:#ae81ff>0</span>);
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    MyKernel<span style=color:#f92672>&lt;&lt;&lt;</span>gridSize, blockSize<span style=color:#f92672>&gt;&gt;&gt;</span>(d_vec1, d_vec2, d_vec3, N); 
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    cudaEventRecord(stop, <span style=color:#ae81ff>0</span>);
</span></span><span style=display:flex><span>    cudaEventSynchronize(stop);
</span></span><span style=display:flex><span>    cudaEventElapsedTime(<span style=color:#f92672>&amp;</span>time, start, stop);
</span></span><span style=display:flex><span>    printf(<span style=color:#e6db74>&#34;Kernel elapsed time:  %3.3f ms </span><span style=color:#ae81ff>\n</span><span style=color:#e6db74>&#34;</span>, time);
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    printf(<span style=color:#e6db74>&#34;Blocksize %i</span><span style=color:#ae81ff>\n</span><span style=color:#e6db74>&#34;</span>, blockSize);
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    cudaMemcpy(h_vec3, d_vec3, N<span style=color:#f92672>*</span><span style=color:#66d9ef>sizeof</span>(<span style=color:#66d9ef>int</span>), cudaMemcpyDeviceToHost);
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>for</span> (<span style=color:#66d9ef>int</span> i<span style=color:#f92672>=</span><span style=color:#ae81ff>0</span>; i<span style=color:#f92672>&lt;</span>N; i<span style=color:#f92672>++</span>) {
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>if</span> (h_vec3[i] <span style=color:#f92672>!=</span> h_vec4[i]) { printf(<span style=color:#e6db74>&#34;Error at i = %i! Host = %i; Device = %i</span><span style=color:#ae81ff>\n</span><span style=color:#e6db74>&#34;</span>, i, h_vec4[i], h_vec3[i]); <span style=color:#66d9ef>return</span>; };
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    printf(<span style=color:#e6db74>&#34;Test passed</span><span style=color:#ae81ff>\n</span><span style=color:#e6db74>&#34;</span>);
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><p><code>cudaOccupancyMaxPotentialBlockSize</code>定义在<code>cuda_runtime.h</code>文件中：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-cpp data-lang=cpp><span style=display:flex><span><span style=color:#66d9ef>template</span><span style=color:#f92672>&lt;</span><span style=color:#66d9ef>class</span> <span style=color:#a6e22e>T</span><span style=color:#f92672>&gt;</span>
</span></span><span style=display:flex><span>__inline__ __host__ CUDART_DEVICE cudaError_t cudaOccupancyMaxPotentialBlockSize(
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>int</span>    <span style=color:#f92672>*</span>minGridSize,
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>int</span>    <span style=color:#f92672>*</span>blockSize,
</span></span><span style=display:flex><span>    T       func,
</span></span><span style=display:flex><span>    size_t  dynamicSMemSize <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>,
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>int</span>     blockSizeLimit <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>)
</span></span><span style=display:flex><span>{
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> <span style=color:#a6e22e>cudaOccupancyMaxPotentialBlockSizeVariableSMem</span>(minGridSize, blockSize, func, __cudaOccupancyB2DHelper(dynamicSMemSize), blockSizeLimit);
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><p>这些参数的含义如下：</p><ul><li><code>minGridSize</code>：返回实现最佳潜在占用率所需的最小网格大小</li><li><code>blockSize</code>：建议的块大小，以实现最大的占用率</li><li><code>func</code>：内核函数</li><li><code>dynamicSMemSize</code>：每块动态共享内存的预定使用量，以字节为单位</li><li><code>blockSizeLimit</code>：最大区块大小，0意味着没有限制。</li></ul><h2 id=references>References</h2><ul><li><p><a href=https://stackoverflow.com/questions/9985912/how-do-i-choose-grid-and-block-dimensions-for-cuda-kernels>https://stackoverflow.com/questions/9985912/how-do-i-choose-grid-and-block-dimensions-for-cuda-kernels</a></p></li><li><p><a href=https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1gee5334618ed4bb0871e4559a77643fc1>https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1gee5334618ed4bb0871e4559a77643fc1</a></p></li></ul><div class=footnotes role=doc-endnotes><hr><ol><li id=fn:1><p><a href=https://developer.nvidia.com/blog/cuda-pro-tip-occupancy-api-simplifies-launch-configuration/>https://developer.nvidia.com/blog/cuda-pro-tip-occupancy-api-simplifies-launch-configuration/</a>&#160;<a href=#fnref:1 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li></ol></div></section><footer class="mt-12 flex flex-wrap"><a class="mb-1.5 rounded-lg bg-black/[3%] px-5 py-1 no-underline hover:bg-black/[6%] ltr:mr-1.5 rtl:ml-1.5 dark:bg-white/[8%] dark:hover:bg-white/[12%]" href=https://fffzlfk.github.io/tags/cuda>CUDA</a></footer><div class="giscus mt-24"></div><script src=https://giscus.app/client.js data-repo=fffzlfk/fffzlfk.github.io data-repo-id=R_kgDOG4ERGw data-category=Q&amp;A data-category-id=DIC_kwDOG4ERG84CBP5t data-mapping=pathname data-strict=1 data-reactions-enabled=0 data-emit-metadata=0 data-input-position=top data-theme=light data-lang=zh-CN data-loading=lazy crossorigin=anonymous async></script></article></main><footer class="mx-auto flex h-[4.5rem] max-w-(--w) items-center px-8 text-xs tracking-wider uppercase opacity-60"><div class=mr-auto>&copy;2025
<a class=link href=https://fffzlfk.github.io/>fffzlfk's Blog</a></div><a class="link mx-6" href=https://gohugo.io/ rel=noopener target=_blank>powered by hugo️️</a>️
<a class=link href=https://github.com/nanxiaobei/hugo-paper rel=noopener target=_blank>hugo-paper</a></footer></body></html>